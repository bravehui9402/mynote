[toc]
# Kafka 简介
Kafka最初是由LinkedIn公司采用Scala语言开发的一个多分区、多副本并且基于ZooKeeper协调的分布式消息系统，现在已经捐献给了Apache基金会。目前Kafka已经定位为一个分布式流式处理平台，它以 高吞吐、可持久化、可水平扩展、支持流处理等多种特性而被广泛应用。

Kafka 是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。

## 使用消息队列的好处
![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207195108350-306987034.png)
- 1. 解耦
允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。
- 2. 可恢复性
系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。 
- 3. 缓冲 
有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。 
- 4. 灵活性 & 峰值处理能力 
在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。
- 5. 异步通信 
很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。 
## 消息队列的两种模式 
- 1. 点对点模式 （一对一，消费者主动拉取数据，消息收到后消息清除） 
消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。 消息被消费以后，queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。
- 2. 发布/订阅模式（一对多，消费者消费数据之后不会清除消息） 
消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。 
![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207200601305-627285371.png)

# Kakfa 架构
![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207200634162-1610685713.png)
- 1.Producer ：消息生产者，就是向 kafka broker 发消息的客户端； 
- 2.Consumer ：消息消费者，向 kafka broker 取消息的客户端； 
- 3.Consumer Group （CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 
- 4.Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个 topic。 
- 5.Topic ：可以理解为一个队列，生产者和消费者面向的都是一个 topic； 
- 6.Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列； 
- 7.Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower (leader 也是副本)。
- 8.leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。  
- 9.follower：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 follower。 
## Kafka 中的信息存储
kafka中消息是以topic（主题）进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。一个topic可以对应多个partition，如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡和水平扩展。 

多个订阅者可以从一个或者多个分区中同时消费数据，以支撑海量数据处理能力。 消息是以追加到分区中的，多个分区顺序写磁盘的总效率要比随机写内存还要高（引用Apache Kafka – A High Throughput Distributed Messaging System的观点），是Kafka高吞吐率的重要保证之一。

 Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。但topic只是逻辑上的概念，也就是一种命名方式，并不真实存在，真正存在的是主题下的分区，分区是物理上的概念。每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据。Producer 生产的数据会被不断追加到该log 文件末端，且每条数据都有自己的 offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费。 
![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207201348031-1519442333.png)
    由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。每个 segment对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic 名称+分区序号。例如，first 这个 topic 有三个分区，则其对应的文件夹为 first-0,first-1,first-2。 
   ![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207201511413-210440027.png)
    index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log 文件的结构示意图。
![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207201542224-835388866.png)
“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元 数据指向对应数据文件中 message 的物理偏移地址

## 分区

- 1.分区的原因
（1）方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了； 
（2）可以提高并发，因为可以以 Partition 为单位读写了。
- 2.分区的原则
我们需要将 producer 发送的数据封装成一个 ProducerRecord 对象 
![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207201928672-805708393.png)
（1）指明 partition 的情况下，直接将指明的值直接作为 partiton 值； 
（2）没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 
数进行取余得到 partition 值； 
（3）既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。 
## 分区的副本机制
假设我们现在有一个主题topic1,topic1下有一个分区partition1，当partition1所在的broker出现故障宕机，kafka就不可用了，因此，为了提高kafka的高可用性和持久性，kafka使用了分区的副本机制。

一个分区可以有多个副本，这些副本保存在不同的broker上。每个分区的副本中都会有一个作为Leader。当一个broker失败时，Leader在这台broker上的分区都会变得不可用，kafka会自动移除Leader，再其他副本中选一个作为新的Leader。 

在通常情况下，增加分区可以提供kafka集群的吞吐量。然而，也应该意识到集群的总分区数或是单台服务器上的分区数过多，会增加不可用及延迟的风险。 

## 分区重新分配 
我们往已经部署好的Kafka集群里面添加机器是最正常不过的需求，而且添加起来非常地方便，我们需要做的事是从已经部署好的Kafka节点中复制相应的配置文件，然后把里面的broker id修改成全局唯一的，最后启动这个节点即可将它加入到现有Kafka集群中。

但是问题来了，新添加的Kafka节点并不会自动地分配数据，所以无法分担集群的负载，除非我们新建一个topic。但是现在我们想手动将部分分区移到新添加的Kafka节点上，Kafka内部提供了相关的工具来重新分布某个topic的分区。 

## 分区分配策略

按照Kafka默认的消费逻辑设定，一个分区只能被同一个消费组（ConsumerGroup）内的一个消费者消费。假设目前某消费组内只有一个消费者C0，订阅了一个topic，这个topic包含7个分区，也就是说这个消费者C0订阅了7个分区，参考下图 
![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207220356047-2095775739.png)
此时消费组内又加入了一个新的消费者C1，按照既定的逻辑需要将原来消费者C0的部分分区分配给消费者C1消费，情形上图（2），消费者C0和C1各自负责消费所分配到的分区，相互之间并无实质性的干扰。

接着消费组内又加入了一个新的消费者C2，如此消费者C0、C1和C2按照上图（3）中的方式各自负责消费所分配到的分区

如果消费者过多，出现了消费者的数量大于分区的数量的情况，就会有消费者分配不到任何分区。参考下图，一共有8个消费者，7个分区，那么最后的消费者C7由于分配不到任何分区进而就无法消费任何消息。
![](https://img2018.cnblogs.com/blog/1550092/201912/1550092-20191207220409155-113737872.png)

消费者客户端参数partition.asssignment.strategy可以配置多个分配策略，彼此之间以逗号分隔。


## Leader的选举
**ISR(In-Sync Replicas)**
所有与Leader部分保持一定程度的副（包括Leader副本在内）本组成ISR。

无论是生产者还是消费者，面向的都是topic，也就是主题中的分区。

主题中可以有多个分区，为了保证高可用和持久性，每个分区会存在有分布在不同broker上的副本。无论是生产还是消费消息，都会只面向多个副本中的Leader进行读写。

可以预见的是,如果某个分区的Leader挂了,那么其它跟随者将会进行选举产生一个新的leader,之后所有的读写就会转移到这个新的Leader上 ，在kafka中,其不是采用常见的多数选举的方式进行副本的Leader选举,而是会在Zookeeper上针对每Topic维护一个称为ISR（in-sync replica，已同步的副本）的集合,显然还有一些副本没有来得及同步。只有这个ISR列表里面的才有资格成为leader (先使用ISR里面的第一个，如果不行依次类推，因为ISR里面的是同步副本，消息是最完整且各个节点都是一样的) 通过ISR,kafka需要的冗余度较低，可以容忍的失败数比较高。假设某个topic有f+1个副本，kafka可以容忍f个不可用,当然,如果全部ISR里面的副本都不可用,也可以选择其他可用的副本,只是存在数据的不一致。 